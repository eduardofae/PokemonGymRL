@article{checkers,
  author={Samuel, A. L.},
  journal={IBM Journal of Research and Development}, 
  title={Some Studies in Machine Learning Using the Game of Checkers}, 
  year={1959},
  volume={3},
  number={3},
  pages={210-229},
  keywords={},
  doi={10.1147/rd.33.0210}}

@article{deepblue,
title = {Deep Blue},
journal = {Artificial Intelligence},
volume = {134},
number = {1},
pages = {57-83},
year = {2002},
issn = {0004-3702},
doi = {https://doi.org/10.1016/S0004-3702(01)00129-1},
url = {https://www.sciencedirect.com/science/article/pii/S0004370201001291},
author = {Murray Campbell and A.Joseph Hoane and Feng-hsiung Hsu},
keywords = {Computer chess, Game tree search, Parallel search, Selective search, Search extensions, Evaluation function},
abstract = {Deep Blue is the chess machine that defeated then-reigning World Chess Champion Garry Kasparov in a six-game match in 1997. There were a number of factors that contributed to this success, including: •a single-chip chess search engine,•a massively parallel system with multiple levels of parallelism,•a strong emphasis on search extensions,•a complex evaluation function, and•effective use of a Grandmaster game database. This paper describes the Deep Blue system, and gives some of the rationale that went into the design decisions behind Deep Blue.}
}

@article{crazystone,
author = {Rémi Coulom},
title ={COMPUTING “ELO RATINGS” OF MOVE PATTERNS IN THE GAME OF GO1},

journal = {ICGA Journal},
volume = {30},
number = {4},
pages = {198-208},
year = {2007},
doi = {10.3233/ICG-2007-30403},
URL = { 
        https://journals.sagepub.com/doi/abs/10.3233/ICG-2007-30403
      },
eprint = { 
        https://journals.sagepub.com/doi/pdf/10.3233/ICG-2007-30403
},
abstract = { Move patterns are an essential method to incorporate domain knowledge into Go-playing programs. This article presents a new Bayesian technique for supervised learning of such patterns from game records. The technique is based on a generalization of Elo ratings. Each sample move in the training data is considered as a victory of a team of pattern features. The “Elo ratings” of individual pattern features are computed from these victories, and will be used in previously unseen positions to compute a probability distribution over legal moves. In this approach, several pattern features may be combined, without an exponential cost in the number of features. Despite a very small number of training games (652), this algorithm outperforms most previous pattern-learning algorithms, both in terms of mean log-evidence (–2.69), and prediction rate (34.9\%). By using these patterns, the 19 × 19 Monte-Carlo program CRAZY STONE reached the level of the strongest classical programs. }
}

@article{atari,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{alphago,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{alphazero,
  title={Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm}, 
  author={David Silver and Thomas Hubert and Julian Schrittwieser and Ioannis Antonoglou and Matthew Lai and Arthur Guez and Marc Lanctot and Laurent Sifre and Dharshan Kumaran and Thore Graepel and Timothy Lillicrap and Karen Simonyan and Demis Hassabis},
  year={2017},
  eprint={1712.01815},
  archivePrefix={arXiv},
  primaryClass={cs.AI},
  url={https://arxiv.org/abs/1712.01815}, 
}

@article{openai5,
  title={Dota 2 with Large Scale Deep Reinforcement Learning},
  author={OpenAI and Christopher Berner and Greg Brockman and Brooke Chan and Vicki Cheung and Przemysław Dębiak and Christy Dennison and David Farhi and Quirin Fischer and Shariq Hashme and Chris Hesse and Rafal Józefowicz and Scott Gray and Catherine Olsson and Jakub Pachocki and Michael Petrov and Henrique Pondé de Oliveira Pinto and Jonathan Raiman and Tim Salimans and Jeremy Schlatter and Jonas Schneider and Szymon Sidor and Ilya Sutskever and Jie Tang and Filip Wolski and Susan Zhang},
  year={2019},
  eprint={1912.06680},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/1912.06680}
}

@article{alphastar,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{dreamer4,
      title={Training Agents Inside of Scalable World Models}, 
      author={Danijar Hafner and Wilson Yan and Timothy Lillicrap},
      year={2025},
      eprint={2509.24527},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2509.24527}, 
}

@INPROCEEDINGS{pokemonbattle,
  author={Simões, David and Reis, Simão and Lau, Nuno and Reis, Luís Paulo},
  booktitle={2020 IEEE International Conference on Autonomous Robot Systems and Competitions (ICARSC)}, 
  title={Competitive Deep Reinforcement Learning over a Pokémon Battling Simulator}, 
  year={2020},
  volume={},
  number={},
  pages={40-45},
  keywords={Games;Machine learning;Switches;Conferences;Learning (artificial intelligence);Convergence;Deep Learning;Reinforcement Learning;Competitive Games;Multi-Agent Systems},
  doi={10.1109/ICARSC49921.2020.9096092}}


